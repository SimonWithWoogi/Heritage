I"F<p><span style="color:red">이번 포스팅에는 귀여운 그림이 전혀 없습니다.</span></p>

<h2 id="1-neural-network"><span style="color:darkblue">1. Neural Network</span></h2>

<p>사람은 감각기관에서 받아들이는 내용에 대해 왜곡이 일어날 때가 있습니다. 이미 가지고 있는 지식때문인데요. 예능 프로그램에 검은 상자 속에 어떤 물컹한 물체를 놔두고 출연자들이 촉감으로 이 물체가 무엇인지 맞추는 게임을 종종 보셨을 겁니다. 재밌죠. 대부분 소스라치게 놀라며 소리지르고 지레 겁을 먹습니다. 만져보면 이게 뭔지 느낌이 올 때가 있습니다. 알고보니 생각했던 것과 전혀 다르죠. 시각으로 생각하면 착시도 있습니다. 잘 못들어서 오해하는 청각에 대한 착각도 있구요. 이렇게 나열하면 사람이니까 실수한다라는 말이 이해가 갑니다.</p>

<p>기계는? 실수하면 잘라버리나요? 기계도 실수할 수 있지라는 말이 나오는 시대가 왔습니다. 바로 <code class="language-plaintext highlighter-rouge">Neural Network</code>에서 시작되는 얘기입니다.</p>

<p><img src="/assets/img/MATLAB/5_1.png" alt="img" /></p>

<h3 id="11-perceptron"><span style="color:darkblue">1.1. Perceptron</span></h3>

<p>먼저 <code class="language-plaintext highlighter-rouge">인공지능</code>을 얘기할 때는 <code class="language-plaintext highlighter-rouge">Perceptron</code> 을 먼저 얘기합니다. <code class="language-plaintext highlighter-rouge">인공지능</code> 이라고해서 진짜로 <code class="language-plaintext highlighter-rouge">Perceptron</code>, <code class="language-plaintext highlighter-rouge">Neuron</code> 신경계를 인공으로 생성하는지 본다면 아니라고 말할 수 있습니다. 다만, <code class="language-plaintext highlighter-rouge">인공지능</code> 이 돌아가는 학습원리, 즉 <code class="language-plaintext highlighter-rouge">Mechanism</code> 을 가만히 보고있으면 정말로 <code class="language-plaintext highlighter-rouge">학습</code>을 거쳐서 어떤 <code class="language-plaintext highlighter-rouge">기준</code>을 만들어서 <code class="language-plaintext highlighter-rouge">인지</code>를 하게 됩니다.</p>

<p><code class="language-plaintext highlighter-rouge">Perceptron</code>, 우리 몸 신경계 기본단위인 <code class="language-plaintext highlighter-rouge">Neuron</code> 으로 구성된 신경망을 인공으로 구현했다라는 의미입니다. 그러니 <code class="language-plaintext highlighter-rouge">Neuron</code> 의 그림을 한번 봅시다. 물론 우리 신경계를 빠삭하게 알 필요까지는 없습니다. 아래 그림에서 가지처럼 뻗어진 <code class="language-plaintext highlighter-rouge">Dendrites</code> 가 <code class="language-plaintext highlighter-rouge">cell body</code> 로 정보를 옮겨 담아 지방층인 <code class="language-plaintext highlighter-rouge">Myelin</code> 으로부터 버퍼역할을 하며 다른 <code class="language-plaintext highlighter-rouge">Neuron</code> 으로 정보를 옮겨줍니다.</p>

<p><img src="/assets/img/MATLAB/5_2.png" alt="img" /></p>

<p>우리에게 <code class="language-plaintext highlighter-rouge">세포체, 수상돌기, 축색돌기</code> 이런 단어는 필요없습니다. <code class="language-plaintext highlighter-rouge">Mechanism</code> 만 이해해서 진짜 비슷하네?라고 느끼면 됩니다. 다시 위 그림에 대해 얘기하면 <code class="language-plaintext highlighter-rouge">Neuron</code> 의 정보전달은 <strong>여러 가지에서 하나의 점으로 모여 다른 뭉치로 이동하는 것입니다.</strong></p>

<p><img src="/assets/img/MATLAB/5_3.png" alt="img" /></p>

<p>지금 위 이미지는 <code class="language-plaintext highlighter-rouge">Single Layer Perceptron</code> 입니다. 얘도 마찬가지로 <strong>여러 가지에서 하나의 점으로 모이죠?</strong></p>

<p><img src="/assets/img/MATLAB/5_4.png" alt="img" /></p>

<p>이 이미지는 <code class="language-plaintext highlighter-rouge">Multi Layer Perceptron</code> 입니다. <strong>모여진 하나의 점에서 다른 뭉치로 이동하네요!</strong></p>

<h3 id="12-neural-network-learning-mechanism"><span style="color:darkblue">1.2. Neural network learning mechanism</span></h3>

<p><code class="language-plaintext highlighter-rouge">Perceptron</code> 의 첫 단락에서 제가 <code class="language-plaintext highlighter-rouge">학습</code> 하는 것을 보다보면~ 이라는 얘기를 했습니다. 이번 내용은 <code class="language-plaintext highlighter-rouge">Neural network</code> 의 학습원리를 얘기합니다.</p>

<h3 id="13-single-layer-perceptron"><span style="color:darkblue">1.3. Single Layer Perceptron</span></h3>

<p><img src="/assets/img/MATLAB/5_5.png" alt="img" /></p>

<p>진짜로 <code class="language-plaintext highlighter-rouge">단층 인공신경망(Single Layer Perceptron)</code> 의 한 모습입니다. <code class="language-plaintext highlighter-rouge">bias</code> 는 출력으로 나온 결과의 중심을 잡아주는 역할입니다. <code class="language-plaintext highlighter-rouge">input nodes</code> 는 입력 데이터를 의미합니다. 바나나로 얘기해보면, 당도, 색감, 크기 등이 있겠네요. 이런 <code class="language-plaintext highlighter-rouge">한 성질들이 하나의 노드(node)</code>가 됩니다. <code class="language-plaintext highlighter-rouge">Weights</code> 는 <code class="language-plaintext highlighter-rouge">학습</code> 에 따라 변하는 가중치입니다. 가중치를 다 합하고 난 다음엔 <code class="language-plaintext highlighter-rouge">활성함수(Activation function)</code> 을 지나 출력이 나오게 됩니다.  <strong>학습에 따라 변하다니요!? 활성함수는 뭘 활성시키죠?!?!</strong> 순차적으로 설명해야하니 지금은 잠깐 잊어주세요.</p>

<p><code class="language-plaintext highlighter-rouge">SLP(Single Layer Perceptron)</code> 은 한번쯤 들어본 <code class="language-plaintext highlighter-rouge">Hidden layer</code> 가 없습니다. 그래서 보면 <code class="language-plaintext highlighter-rouge">Input layer, Output layer</code> 이게 전부입니다. 그렇다면 이제 차근차근 학습원리를 볼까요?</p>

<table>
  <thead>
    <tr>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>-1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>-1</td>
    </tr>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>-1</td>
    </tr>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-1</td>
    </tr>
  </tbody>
</table>

<p>입력 노드가 세개가 있으니까 처음 가중치를 0.333으로 해서 계산을 해보겠습니다. 참고로 활성함수는 <code class="language-plaintext highlighter-rouge">sign function</code> 입니다.(0, 1이 아닌 1과 -1로 구분짓기에)</p>

<p><img src="/assets/img/MATLAB/5_6.png" alt="img" /></p>

<p>아래는 가중치의 합에다가 sign을 한 결과입니다. 어떻게, 과연 맞을까요?
\(\begin{array}{l}
Y\ =\ sign(0.333X_1+0.333X_2+0.333X_3)
\end{array}\\\)</p>

<table>
  <thead>
    <tr>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>Y(Predict)</th>
      <th>Y(Real)</th>
      <th>Diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.2955</td>
      <td>-1</td>
      <td>1.2955</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0.5646</td>
      <td>1</td>
      <td>0.4354</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0.5646</td>
      <td>1</td>
      <td>0.4354</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0.7833</td>
      <td>1</td>
      <td>0.2167</td>
    </tr>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0.2955</td>
      <td>-1</td>
      <td>1.2955</td>
    </tr>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.2955</td>
      <td>-1</td>
      <td>1.2955</td>
    </tr>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0.5646</td>
      <td>1</td>
      <td>0.4354</td>
    </tr>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-1</td>
      <td>1.0000</td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/img/MATLAB/5_7.png" alt="img" /></p>

<p>많이 틀리죠? 그런데 뭔가 패턴이 보입니다. -1이 나와야하는 애들과 1이 나와야하는 애들과 비슷한 숫자를 가지고 있네요.</p>

<p>바로 0.3~0.56구간을 기준으로 높으면 1, 낮으면 -1이라고 볼 수 있네요. 이제 <code class="language-plaintext highlighter-rouge">활성함수(sign function)</code>에 대해서 말씀드리겠습니다.</p>

<p><img src="/assets/img/MATLAB/5_8.png" alt="img" /></p>

<p><code class="language-plaintext highlighter-rouge">sign</code> 은 위와 같은 그래프를 그립니다. <code class="language-plaintext highlighter-rouge">sign(0)</code> 은 0이구요. <code class="language-plaintext highlighter-rouge">sign(90)</code> 은 1이고 <code class="language-plaintext highlighter-rouge">sign(270)</code> 은 -1입니다.  근데 사실 <code class="language-plaintext highlighter-rouge">sign function</code> 은 이게 아닙니다. 왜냐면 <code class="language-plaintext highlighter-rouge">sign function</code> 은 부호화에 사용될 때 사용하거든요.</p>

<p><img src="/assets/img/MATLAB/5_9.png" alt="img" /></p>

<p>그러니까, 양수면 1을 만들어주고, 0이면 0, 음수면 -1을 만들어주는 부호화 함수입니다. 그런데 이런 부호화 함수를 써도 우리는 <code class="language-plaintext highlighter-rouge">Y (Predict)</code> 가 양수니까 다 1이 나오겠죠?</p>

<p><code class="language-plaintext highlighter-rouge">bias</code> 를 0.3과 0.5사이 구간인 0.4를 붙이겠습니다.</p>

<p>[\begin{array}{l}
Y\ =\ sign(\sum_{i=1}^3 0.333\cdot X_i - 0.4)
\end{array}\]</p>

<table>
  <thead>
    <tr>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>Y(Val - bias)</th>
      <th>Y(Sign)</th>
      <th>Y(Real)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.333 - 0.4</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0.666 - 0.4</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0.666 - 0.4</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0.999 - 0.4</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0.333 - 0.4</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.333 - 0.4</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0.666 - 0.4</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0 - 0.4</td>
      <td>-1</td>
      <td>-1</td>
    </tr>
  </tbody>
</table>

<h3 id="14-multi-layer-perceptron"><span style="color:darkblue">1.4. Multi Layer Perceptron</span></h3>

<p><img src="/assets/img/MATLAB/5_10.png" alt="img" /></p>

<p>방금 <code class="language-plaintext highlighter-rouge">SLP</code> 에서는 <code class="language-plaintext highlighter-rouge">Weight</code>  변경을 위한 학습이나 뒤로 와서 다시 연산하는 <code class="language-plaintext highlighter-rouge">Backward propagation</code> 에 대한 설명이 없었습니다. 그래서 이번에는 <code class="language-plaintext highlighter-rouge">Hidden layer</code> 가 추가된 <code class="language-plaintext highlighter-rouge">다층 신경망(MLP, Multi Layer Perceptron)</code> 으로 설명드리겠습니다.</p>

<table>
  <thead>
    <tr>
      <th>X1</th>
      <th>X2</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>위 조건을 봅시다. XOR회로입니다. <code class="language-plaintext highlighter-rouge">SLP</code> 에서는 학습이 안됩니다. 이유는 <code class="language-plaintext highlighter-rouge">2. Implement</code> 에서 확인할 수 있습니다. 그러나 <code class="language-plaintext highlighter-rouge">MLP</code> 에서는 가능합니다. 이제 <code class="language-plaintext highlighter-rouge">Perceptron</code> 을 확인해봅시다. <code class="language-plaintext highlighter-rouge">MLP</code> 니까 명분을 살려야겠죠? <code class="language-plaintext highlighter-rouge">Hidden layer</code> 를 하나 추가하여 만들어보겠습니다.</p>

<p><img src="/assets/img/MATLAB/5_11.png" alt="img" /></p>

<p>아래는 수식입니다.</p>

<p>[\begin{array}{l}
h_1\ =\ w^2<em>{11}x_1+w^2</em>{21}x_2+c_1<br />
h_2\ =\ w^2<em>{12}x_1+w^2</em>{22}x_2+c_2<br />
<br />
\hat{h} = \hat{w}^{2’}\hat{x}+\hat{c}<br />
\hat{h} = \begin{bmatrix}
h_{1}<br />
h_{2}
\end{bmatrix}\qquad
\hat{w}^2 = \begin{bmatrix}
w^2<em>{11}\ w^2</em>{12}<br />
w^2<em>{21}\ w^2</em>{22}<br />
\end{bmatrix} \qquad
\hat{x} = \begin{bmatrix}
x_{1}<br />
x_{2}
\end{bmatrix}<br />
<br />
\therefore \ y=\hat{w}^{3’}\hat{h}+b<br />
\hat{w}^3=  \begin{bmatrix}
w^3<em>{11} <br />
w^3</em>{21}
\end{bmatrix}</p>

<p>\end{array}\]</p>

<p>구조는 이렇습니다. 사실 <code class="language-plaintext highlighter-rouge">MLP</code> 는 간단하지 않기때문에 처음 <code class="language-plaintext highlighter-rouge">순전파(forward propagation)</code> 부터 설명하겠습니다. 순서대로 계산한다는 개념이죠. 이번에는 <code class="language-plaintext highlighter-rouge">input node</code> 가 2개니까 <code class="language-plaintext highlighter-rouge">weight</code> 를 모두 0.5씩 걸어두고 진행해보겠습니다. <code class="language-plaintext highlighter-rouge">c와 b</code> 는 <code class="language-plaintext highlighter-rouge">bias</code> 개념이니까 1부터 시작하겠습니다. 계산은 <code class="language-plaintext highlighter-rouge">MATLAB</code>으로 합니다.</p>

<p><img src="/assets/img/MATLAB/5_12.png" alt="img" /></p>

<table>
  <thead>
    <tr>
      <th>X1</th>
      <th>X2</th>
      <th>h1</th>
      <th>h2</th>
      <th>Y(Predict)</th>
      <th>Y(Real)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>1.5</td>
      <td>1.5</td>
      <td>2.5</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>1.5</td>
      <td>1.5</td>
      <td>2.5</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>제법 많이 다르죠? <code class="language-plaintext highlighter-rouge">Sign function</code> 을 적용하기에도, 즉  <code class="language-plaintext highlighter-rouge">0과 1로</code> 부호화하기가 어렵습니다. <code class="language-plaintext highlighter-rouge">Layer</code> 를 추가했으니 <code class="language-plaintext highlighter-rouge">h</code> 를 기준으로 다시 표를 그려보겠습니다.</p>

<table>
  <thead>
    <tr>
      <th>h1</th>
      <th>h2</th>
      <th>Y(Predict)</th>
      <th>Y(Real)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <td>1.5</td>
      <td>1.5</td>
      <td>2.5</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2.0</td>
      <td>2.0</td>
      <td>3</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>이렇게보니 <code class="language-plaintext highlighter-rouge">h1, h2</code> 가 너무 똑같이 나오네요. <code class="language-plaintext highlighter-rouge">c</code> 를 조정할 필요가 있어보입니다. 그래서 보통 <code class="language-plaintext highlighter-rouge">MLP</code> 에 들어가는 초기 <code class="language-plaintext highlighter-rouge">c와 weight</code> 는 이런 이유로 균일하게 구성하지 않습니다. 사실 똑같이 구성해도 큰 문제가 없으나 결과가 조금 느리게 나올 뿐입니다.</p>

<p><code class="language-plaintext highlighter-rouge">c를 1과 0으로 두개 구성했다면 h1 = [1 1.5 2.0]이고 h2=[0. 0.5 1.0]이니 h1과 h2를 조합하여 잘 사용할 수 있습니다. 지금은 두 h가 똑같아 하나를 없애도 괜찮겠다라는 생각이 들게 합니다.</code></p>

<h3 id="2-backpropagation"><span style="color:darkblue">2. Backpropagation</span></h3>

<p>다음부터는 <code class="language-plaintext highlighter-rouge">backpropagation</code> 설명입니다.</p>

<p><a href="https://simonwithwoogi.github.io/SimonWithWoogi.github.io/posts/matlabneuralnet2/">backpropagation</a></p>

:ET